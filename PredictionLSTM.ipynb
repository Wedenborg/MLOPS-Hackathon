{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "import tensorflow as tf\n",
    "import codecarbon\n",
    "from codecarbon import EmissionsTracker\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dda9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tracker\n",
    "tracker = EmissionsTracker(project_name=\"tensorflow_experiment\")\n",
    "tracker.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6be91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/DailyDelhiClimateTrain.csv'\n",
    "df = pd.read_csv(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a W&B run and set hyperparameters\n",
    "wandb.init(\n",
    "    project=\"MLOPS-Hackathon\",   # Name of your project\n",
    "    #entity=\"emiliewedenborg-technical-university-of-denmark\",  # Replace with your W&B entity\n",
    "    entity=\"amoal-danmarks-tekniske-universitet-dtu\",\n",
    "    name=\"temperature-forecasting-lstm\",  # Name of the run\n",
    "\n",
    "    config={\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"optimizer\": \"adam\"\n",
    "    }\n",
    ")\n",
    "\n",
    "config = wandb.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01823689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
    "df.set_index('date', inplace= True)\n",
    "\n",
    "n_cols = 1\n",
    "dataset = df[\"meantemp\"]\n",
    "dataset = pd.DataFrame(dataset)\n",
    "data = dataset.values\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range= (0, 1))\n",
    "scaled_data = scaler.fit_transform(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3484d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.75)\n",
    "test_size = len(data) - train_size\n",
    "print(\"Train Size :\",train_size,\"Test Size :\",test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scaled_data[0:train_size, :]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Training set with 60 time-steps\n",
    "x_train = []\n",
    "y_train = []\n",
    "time_steps = 60\n",
    "n_cols = 1\n",
    "\n",
    "for i in range(time_steps, len(scaled_data)):\n",
    "    x_train.append(scaled_data[i-time_steps:i, :n_cols])\n",
    "    y_train.append(scaled_data[i, :n_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the input to (n_samples, time_steps, n_feature)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd69fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(50, return_sequences= True, input_shape= (x_train.shape[1], n_cols)),\n",
    "    LSTM(64, return_sequences= False),\n",
    "    Dense(32),\n",
    "    Dense(16),\n",
    "    Dense(n_cols)\n",
    "])\n",
    "\n",
    "model.compile(optimizer= 'adam', loss= 'mse' , metrics= [\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb385e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    batch_size=32, \n",
    "    callbacks=[WandbCallback(save_graph=False)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588def77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"mean_absolute_error\"])\n",
    "plt.legend(['Mean Squared Error','Mean Absolute Error'])\n",
    "plt.title(\"Losses\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop tracker and get emissions\n",
    "emissions = tracker.stop()\n",
    "print(f\"Emissions: {emissions} kg COâ‚‚eq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc23c5e",
   "metadata": {},
   "source": [
    "# Do actual predictions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6beb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a testing set with 60 time-steps and 1 output\n",
    "time_steps = 60\n",
    "test_data = scaled_data[train_size - time_steps:, :]\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "n_cols = 1\n",
    "\n",
    "for i in range(time_steps, len(test_data)):\n",
    "    x_test.append(test_data[i-time_steps:i, 0:n_cols])\n",
    "    y_test.append(test_data[i, 0:n_cols])\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e54f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Prediction\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse predictions scaling\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535991bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse y_test scaling\n",
    "y_test = scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513effc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(np.mean( y_test - predictions )**2).round(2)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daaf171",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})\n",
    "preds_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e172210",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 6))\n",
    "plt.plot(preds_acts['Predictions'])\n",
    "plt.plot(preds_acts['Actuals'])\n",
    "plt.legend(['Predictions', 'Actuals'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c50d27",
   "metadata": {},
   "source": [
    "# Predict more than just the temp (multivariate predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 4\n",
    "cols = list(df.loc[:, ['meantemp', 'humidity', 'wind_speed', 'meanpressure']])\n",
    "dataset = df[cols]\n",
    "dataset = pd.DataFrame(dataset)\n",
    "data = dataset.values\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range= (0, 1))\n",
    "scaled_data = scaler.fit_transform(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.75)\n",
    "test_size = len(data) - train_size\n",
    "print(\"Train Size :\",train_size,\"Test Size :\",test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835cb102",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scaled_data[0:train_size, :]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5073714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Training set with 60 time-steps\n",
    "x_train = []\n",
    "y_train = []\n",
    "time_steps = 60\n",
    "n_cols = 4\n",
    "\n",
    "for i in range(time_steps, len(train_data)):\n",
    "    x_train.append(train_data[i-time_steps:i, :n_cols])\n",
    "    y_train.append(train_data[i, :n_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e718479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the input to (n_samples, time_steps, n_feature)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_cols))\n",
    "x_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    LSTM(50, return_sequences= True, input_shape= (x_train.shape[1], n_cols)),\n",
    "    LSTM(64, return_sequences= False),\n",
    "    Dense(32),\n",
    "    Dense(16),\n",
    "    Dense(n_cols)\n",
    "])\n",
    "\n",
    "model2.compile(optimizer= 'adam', loss= 'mse' , metrics= [\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be034513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "model2 = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation=\"relu\", input_shape=(x_train.shape[1], n_cols)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation=\"relu\"),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(n_cols)\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mean_absolute_error\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    batch_size=32, \n",
    "    callbacks=[WandbCallback(save_graph=False)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a120fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(history2.history[\"loss\"])\n",
    "plt.plot(history2.history[\"mean_absolute_error\"])\n",
    "plt.legend(['Mean Squared Error','Mean Absolute Error'])\n",
    "plt.title(\"Losses\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_mag = tfmot.sparsity.keras.prune_low_magnitude\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=105)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_mag(model2, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6940d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 58, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPoolin  (None, 29, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 27, 64)            6208      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 13, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 832)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                53312     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61761 (241.25 KB)\n",
      "Trainable params: 61761 (241.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 20:20:50] Energy consumed for RAM : 0.013741 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:20:50] Delta energy consumed for CPU with constant : 0.001501 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:20:50] Energy consumed for All CPU : 0.247546 kWh\n",
      "[codecarbon INFO @ 20:20:51] Energy consumed for all GPUs : 0.008545 kWh. Total GPU Power : 13.870829965921862 W\n",
      "[codecarbon INFO @ 20:20:51] 0.269832 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:21:06] Energy consumed for RAM : 0.013824 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:21:06] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:21:06] Energy consumed for All CPU : 0.249046 kWh\n",
      "[codecarbon INFO @ 20:21:06] Energy consumed for all GPUs : 0.008604 kWh. Total GPU Power : 14.137675318960005 W\n",
      "[codecarbon INFO @ 20:21:06] 0.271475 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:21:20] Energy consumed for RAM : 0.013908 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:21:21] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:21:21] Energy consumed for All CPU : 0.250546 kWh\n",
      "[codecarbon INFO @ 20:21:21] Energy consumed for all GPUs : 0.008655 kWh. Total GPU Power : 12.177105911069795 W\n",
      "[codecarbon INFO @ 20:21:21] 0.273109 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:21:36] Energy consumed for RAM : 0.013991 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:21:36] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:21:36] Energy consumed for All CPU : 0.252047 kWh\n",
      "[codecarbon INFO @ 20:21:36] Energy consumed for all GPUs : 0.008701 kWh. Total GPU Power : 11.166061637247797 W\n",
      "[codecarbon INFO @ 20:21:36] 0.274739 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:21:36] 0.016563 g.CO2eq/s mean an estimation of 522.3199145401304 kg.CO2eq/year\n",
      "[codecarbon INFO @ 20:21:51] Energy consumed for RAM : 0.014074 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:21:51] Delta energy consumed for CPU with constant : 0.001502 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:21:51] Energy consumed for All CPU : 0.253548 kWh\n",
      "[codecarbon INFO @ 20:21:51] Energy consumed for all GPUs : 0.008743 kWh. Total GPU Power : 10.083901317717002 W\n",
      "[codecarbon INFO @ 20:21:51] 0.276366 kWh of electricity used since the beginning.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tf_keras as keras\n",
    "from tf_keras import layers, models\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# ---- Rebuild your model with tf_keras ----\n",
    "n_cols = x_train.shape[2]  # keep your original shapes\n",
    "model2 = models.Sequential([\n",
    "    layers.Conv1D(filters=32, kernel_size=3, activation=\"relu\",\n",
    "                  input_shape=(x_train.shape[1], n_cols)),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(filters=64, kernel_size=3, activation=\"relu\"),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(n_cols)   # regression head\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=keras.optimizers.Adam(),\n",
    "               loss=keras.losses.MeanSquaredError(),\n",
    "               metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "model2.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    batch_size=32, \n",
    "    callbacks=[WandbCallback(save_graph=False)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae5f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv1d  (None, 58, 32)            226       \n",
      " _4 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 29, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_conv1d  (None, 27, 64)            12354     \n",
      " _5 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 13, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 832)               0         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 64)                106562    \n",
      " 6 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 32)                4130      \n",
      " 7 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 1)                 67        \n",
      " 8 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123339 (481.81 KB)\n",
      "Trainable params: 61761 (241.25 KB)\n",
      "Non-trainable params: 61578 (240.56 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 2s 24ms/step - loss: 0.0031 - mean_absolute_error: 0.0426 - val_loss: 0.0047 - val_mean_absolute_error: 0.0565\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0026 - mean_absolute_error: 0.0395 - val_loss: 0.0066 - val_mean_absolute_error: 0.0694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 20:20:05] Energy consumed for RAM : 0.013491 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:20:05] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:20:05] Energy consumed for All CPU : 0.243045 kWh\n",
      "[codecarbon INFO @ 20:20:05] Energy consumed for all GPUs : 0.008374 kWh. Total GPU Power : 14.116190009267912 W\n",
      "[codecarbon INFO @ 20:20:05] 0.264910 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:20:20] Energy consumed for RAM : 0.013574 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:20:20] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:20:20] Energy consumed for All CPU : 0.244545 kWh\n",
      "[codecarbon INFO @ 20:20:20] Energy consumed for all GPUs : 0.008427 kWh. Total GPU Power : 12.888268934906277 W\n",
      "[codecarbon INFO @ 20:20:20] 0.266547 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:20:35] Energy consumed for RAM : 0.013658 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:20:35] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:20:35] Energy consumed for All CPU : 0.246045 kWh\n",
      "[codecarbon INFO @ 20:20:35] Energy consumed for all GPUs : 0.008487 kWh. Total GPU Power : 14.414364694449436 W\n",
      "[codecarbon INFO @ 20:20:35] 0.268190 kWh of electricity used since the beginning.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Pruning setup (PolynomialDecay) ----\n",
    "end_step = 105  # must be an int\n",
    "\n",
    "pruning_params = {\n",
    "    \"pruning_schedule\": tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.50,\n",
    "        final_sparsity=0.80,\n",
    "        begin_step=0,\n",
    "        end_step=end_step\n",
    "    )\n",
    "}\n",
    "\n",
    "def prune_layer(layer):\n",
    "    # Prune Conv1D and Dense (you can add more layer types if needed)\n",
    "    if isinstance(layer, (layers.Conv1D, layers.Dense)):\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "    return layer\n",
    "\n",
    "# Clone the model with pruned layers\n",
    "model_for_pruning = keras.models.clone_model(model2, clone_function=prune_layer)\n",
    "\n",
    "model_for_pruning.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    ")\n",
    "\n",
    "model_for_pruning.summary()\n",
    "\n",
    "# ---- Train with pruning callback ----\n",
    "callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "\n",
    "history = model_for_pruning.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=validation_split,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ---- Strip pruning wrappers for export/inference ----\n",
    "model_stripped = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "model_stripped.save(\"pruned_1d_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a713bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a testing set with 60 time-steps and 1 output\n",
    "time_steps = 60\n",
    "test_data = scaled_data[train_size - time_steps:, :]\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "n_cols = 4\n",
    "\n",
    "for i in range(time_steps, len(test_data)):\n",
    "    x_test.append(test_data[i-time_steps:i, 0:n_cols])\n",
    "    y_test.append(test_data[i, 0:n_cols])\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5406572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Prediction\n",
    "predictions = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7025c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse y_test scaling\n",
    "y_test = scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ee8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(np.mean( y_test - predictions )**2).round(2)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336777da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_end(Xin, new_input):\n",
    "    timestep = 60\n",
    "    for i in range(timestep - 1):\n",
    "        Xin[:, i, :] = Xin[:, i+1, :]\n",
    "    Xin[:, timestep - 1, :] = new_input\n",
    "    return Xin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = 30\n",
    "forcast = []\n",
    "Xin = x_test[-1 :, :, :]\n",
    "time = []\n",
    "for i in range(0, future):\n",
    "    out = model2.predict(Xin, batch_size=5)\n",
    "    forcast.append(out[0]) \n",
    "    print(forcast)\n",
    "    Xin = insert_end(Xin, out[0, 0]) \n",
    "    time.append(pd.to_datetime(df.index[-1]) + timedelta(days=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ece867",
   "metadata": {},
   "outputs": [],
   "source": [
    "forcasted_output = np.asanyarray(forcast)   \n",
    "forcasted_output = scaler.inverse_transform(forcasted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "forcasted_output = pd.DataFrame(forcasted_output)\n",
    "date = pd.DataFrame(time)\n",
    "df_result = pd.concat([date,forcasted_output], axis=1)\n",
    "df_result.columns = \"Date\", 'meantemp', 'humidity', 'wind_speed', 'meanpressure'\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title('Next 30 Days')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(df['meantemp'])\n",
    "plt.plot(df_result.set_index('Date')[['meantemp']])\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Temp' ,fontsize=18)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(df['humidity'])\n",
    "plt.plot(df_result.set_index('Date')[['humidity']])\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('humidity' ,fontsize=18)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(df['wind_speed'])\n",
    "plt.plot(df_result.set_index('Date')[['wind_speed']])\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('wind_speed' ,fontsize=18)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(df['meanpressure'])\n",
    "plt.plot(df_result.set_index('Date')[['meanpressure']])\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('meanpressure' ,fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"temperature_forecasting_cnn.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52530e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 20:17:05] Energy consumed for RAM : 0.012492 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:17:05] Delta energy consumed for CPU with constant : 0.001501 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:17:05] Energy consumed for All CPU : 0.225044 kWh\n",
      "[codecarbon INFO @ 20:17:05] Energy consumed for all GPUs : 0.007675 kWh. Total GPU Power : 14.672299484535904 W\n",
      "[codecarbon INFO @ 20:17:05] 0.245211 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:17:20] Energy consumed for RAM : 0.012575 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:17:20] Delta energy consumed for CPU with constant : 0.001499 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:17:20] Energy consumed for All CPU : 0.226543 kWh\n",
      "[codecarbon INFO @ 20:17:20] Energy consumed for all GPUs : 0.007732 kWh. Total GPU Power : 13.783471994240145 W\n",
      "[codecarbon INFO @ 20:17:20] 0.246851 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:17:35] Energy consumed for RAM : 0.012658 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:17:35] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:17:35] Energy consumed for All CPU : 0.228043 kWh\n",
      "[codecarbon INFO @ 20:17:35] Energy consumed for all GPUs : 0.007791 kWh. Total GPU Power : 14.074506232514683 W\n",
      "[codecarbon INFO @ 20:17:35] 0.248493 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:17:35] 0.016528 g.CO2eq/s mean an estimation of 521.2277688382214 kg.CO2eq/year\n",
      "[codecarbon INFO @ 20:17:50] Energy consumed for RAM : 0.012742 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:17:50] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:17:50] Energy consumed for All CPU : 0.229544 kWh\n",
      "[codecarbon INFO @ 20:17:50] Energy consumed for all GPUs : 0.007850 kWh. Total GPU Power : 14.079263291882764 W\n",
      "[codecarbon INFO @ 20:17:50] 0.250135 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:18:05] Energy consumed for RAM : 0.012825 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:18:05] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:18:05] Energy consumed for All CPU : 0.231043 kWh\n",
      "[codecarbon INFO @ 20:18:05] Energy consumed for all GPUs : 0.007910 kWh. Total GPU Power : 14.536691857209629 W\n",
      "[codecarbon INFO @ 20:18:05] 0.251779 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:18:20] Energy consumed for RAM : 0.012908 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:18:20] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:18:20] Energy consumed for All CPU : 0.232543 kWh\n",
      "[codecarbon INFO @ 20:18:20] Energy consumed for all GPUs : 0.007968 kWh. Total GPU Power : 13.795240876040518 W\n",
      "[codecarbon INFO @ 20:18:20] 0.253419 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:18:35] Energy consumed for RAM : 0.012991 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:18:35] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:18:35] Energy consumed for All CPU : 0.234043 kWh\n",
      "[codecarbon INFO @ 20:18:35] Energy consumed for all GPUs : 0.008025 kWh. Total GPU Power : 13.591936185297595 W\n",
      "[codecarbon INFO @ 20:18:35] 0.255059 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:18:50] Energy consumed for RAM : 0.013075 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:18:50] Delta energy consumed for CPU with constant : 0.001501 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:18:50] Energy consumed for All CPU : 0.235544 kWh\n",
      "[codecarbon INFO @ 20:18:50] Energy consumed for all GPUs : 0.008083 kWh. Total GPU Power : 14.023327288329439 W\n",
      "[codecarbon INFO @ 20:18:50] 0.256702 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:19:05] Energy consumed for RAM : 0.013158 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:19:05] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:19:05] Energy consumed for All CPU : 0.237044 kWh\n",
      "[codecarbon INFO @ 20:19:05] Energy consumed for all GPUs : 0.008139 kWh. Total GPU Power : 13.50132288222829 W\n",
      "[codecarbon INFO @ 20:19:05] 0.258341 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:19:20] Energy consumed for RAM : 0.013241 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:19:20] Delta energy consumed for CPU with constant : 0.001501 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:19:20] Energy consumed for All CPU : 0.238545 kWh\n",
      "[codecarbon INFO @ 20:19:20] Energy consumed for all GPUs : 0.008197 kWh. Total GPU Power : 13.832015545283232 W\n",
      "[codecarbon INFO @ 20:19:20] 0.259983 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:19:35] Energy consumed for RAM : 0.013325 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:19:35] Delta energy consumed for CPU with constant : 0.001500 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:19:35] Energy consumed for All CPU : 0.240044 kWh\n",
      "[codecarbon INFO @ 20:19:35] Energy consumed for all GPUs : 0.008256 kWh. Total GPU Power : 14.225294024301725 W\n",
      "[codecarbon INFO @ 20:19:35] 0.261625 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:19:35] 0.016590 g.CO2eq/s mean an estimation of 523.1949718566723 kg.CO2eq/year\n",
      "[codecarbon INFO @ 20:19:50] Energy consumed for RAM : 0.013408 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 20:19:50] Delta energy consumed for CPU with constant : 0.001501 kWh, power : 360.0 W\n",
      "[codecarbon INFO @ 20:19:50] Energy consumed for All CPU : 0.241545 kWh\n",
      "[codecarbon INFO @ 20:19:50] Energy consumed for all GPUs : 0.008315 kWh. Total GPU Power : 14.038762713372424 W\n",
      "[codecarbon INFO @ 20:19:50] 0.263268 kWh of electricity used since the beginning.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_stripped)\n",
    "\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]    # Uncomment this line for Model 2 and Model 3\n",
    "\n",
    "#def representative_data_gen():                          # Uncomment the following 5 lines for Model 3\n",
    "#    for input_value, _ in test_batches.take(200):\n",
    "#        yield [input_value]\n",
    "#converter.representative_dataset = representative_data_gen\n",
    "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "tflite_models_dir = pathlib.Path(\"\")\n",
    "\n",
    "tflite_model_file = tflite_models_dir/'model_pruned.tflite'     # Change the filename here for Model2 and Model3!\n",
    "x = tflite_model_file.write_bytes(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecafa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run this cell each time to test your model's accuracy (make sure to change the filename)\n",
    "from tqdm import tqdm\n",
    "from ai_edge_litert.interpreter import Interpreter\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "tflite_model_file = '/content/model1.tflite'                 # Change the filename here for Model 2 and 3\n",
    "interpreter = Interpreter(model_path=tflite_model_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "test_labels, test_imgs = [], []\n",
    "for img, label in tqdm(test_batches.take(100)):\n",
    "    interpreter.set_tensor(input_index, img)\n",
    "    interpreter.invoke()\n",
    "    predictions.append(interpreter.get_tensor(output_index))\n",
    "\n",
    "    test_labels.append(label.numpy()[0])\n",
    "    test_imgs.append(img)\n",
    "\n",
    "# For model 1, I got 204.13 it/s\n",
    "# For model 2, I got 156.91 it/s\n",
    "# For model 3, I got 134.71s it/s\n",
    "# Note: since the it/s will depend on the computer on which your Colab VM\n",
    "#       instance is running -- we would expect it to vary a bit.\n",
    "\n",
    "score = 0\n",
    "for item in range(0,100):\n",
    "  prediction=np.argmax(predictions[item])\n",
    "  label = test_labels[item]\n",
    "  if prediction==label:\n",
    "    score=score+1\n",
    "\n",
    "print(\"Out of 100 predictions I got \" + str(score) + \" correct\")\n",
    "\n",
    "# Model 1 - 100 Correct\n",
    "# Model 2 - 99 Correct\n",
    "# Model 3 - 99 Correct\n",
    "# Note: since training starts from a random intialization it would not be\n",
    "#       surprising if your result is off by 1 or 2 correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4dbd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab40b03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
